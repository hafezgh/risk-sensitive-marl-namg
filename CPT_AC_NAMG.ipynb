{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hafezgh/nested-cpt-actor-critic/blob/main/lottery.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "plrup0kheEhF",
        "outputId": "03a5cc80-eee9-4ef7-e294-c043f960ed13"
      },
      "outputs": [],
      "source": [
        "from cpt import *\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import copy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "7JwgOhJKeEhI"
      },
      "outputs": [],
      "source": [
        "S = 5\n",
        "A = 3\n",
        "N = 4\n",
        "seed = 2045\n",
        "np.random.seed(seed)\n",
        "P = np.random.rand(S,int(A**N),S) + 0.01\n",
        "for s in range(S):\n",
        "    for a in range(int(A**N)):\n",
        "        P[s,a] /= np.sum(P[s,a,:])\n",
        "state_trans = P\n",
        "w = np.random.uniform(size=(N,N))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "class Agent():\n",
        "    def __init__(self, id, S, A, num_neigh, state_trans, n_max=50, discount=0.99, alpha_ = 0.65, beta_ = 0.65,\\\n",
        "                 lambda_ = 2.6, gamma_pos = 0.69, gamma_neg = 0.69):\n",
        "        self.id = id\n",
        "        self.S = S\n",
        "        self.A = A\n",
        "        self.num_visible_agents = num_neigh + 1\n",
        "        self.discount = discount\n",
        "        self.n_max = n_max\n",
        "        self.v = np.zeros((S,))\n",
        "        self.theta = np.random.rand(S,A)\n",
        "        self.pi = (1/A)*np.ones((S,A))\n",
        "        self.state_trans = state_trans\n",
        "        self.alpha_ = alpha_\n",
        "        self.beta_ = beta_\n",
        "        self.lambda_ = lambda_\n",
        "        self.gamma_pos = gamma_pos\n",
        "        self.gamma_neg = gamma_neg\n",
        "    \n",
        "    def policy(self, s):\n",
        "        self.pi[s] = np.exp(self.theta[s])/np.sum(np.exp(self.theta[s]))\n",
        "            \n",
        "    def sel_action(self, s):\n",
        "        self.a = np.random.choice(A, p=self.pi[s].ravel())\n",
        "        return self.a\n",
        "    \n",
        "    def sel_action_next(self, sn):\n",
        "        self.next_a = np.random.choice(A, p=self.pi[sn].ravel())\n",
        "        return self.next_a\n",
        "\n",
        "    def calculate_joint_a(self, acts):\n",
        "        joint_a = 0\n",
        "        for i in range(self.num_visible_agents):\n",
        "            joint_a += acts[i]*self.A**(self.num_visible_agents-i-1)\n",
        "        return joint_a\n",
        "\n",
        "    def lr_critic(self, it):\n",
        "        return 0.1/(it**0.75)\n",
        "    \n",
        "    def lr_actor(self,it):\n",
        "        return 0.1/(it**0.5)\n",
        "\n",
        "    def cpt_delta(self, s, acts, Rp, Rsigma):\n",
        "        delta = 0\n",
        "        acts_n_ = copy.deepcopy(acts)\n",
        "        samples = np.zeros((self.n_max, 1))\n",
        "        for i in range(self.n_max):\n",
        "            a = self.sel_action(s)\n",
        "            acts_n_[self.id] = a\n",
        "            sigma = (np.sum(acts_n_+1) - (a+1))/(self.num_visible_agents-1)\n",
        "            joint_a = self.calculate_joint_a(acts_n_)\n",
        "            r = Rp[self.id,s] + Rsigma[s] * sigma\n",
        "            sn = get_next_state(s, joint_a, self.state_trans)\n",
        "            samples[i] = r + self.v[sn]\n",
        "        est_v_s = cpt_estimate_from_samples(samples, self.alpha_, self.beta_, self.lambda_, self.gamma_pos, self.gamma_neg)\n",
        "        delta = float(est_v_s - self.v[s])\n",
        "        return delta\n",
        "\n",
        "    def mu_cpt(self, acts, Rp, Rsigma):\n",
        "        weights = np.zeros((self.S,self.S))\n",
        "        acts_ = copy.deepcopy(acts)\n",
        "        for sn in range(self.S):\n",
        "            for s in range(self.S):\n",
        "                samples = np.zeros((self.n_max, 1))\n",
        "                for i in range(self.n_max):\n",
        "                    a = self.sel_action(s)\n",
        "                    acts_[self.id] = a\n",
        "                    sigma = (np.sum(acts_+1) - (a+1))/(self.num_visible_agents-1)\n",
        "                    r = Rp[self.id,s] + Rsigma[s] * sigma\n",
        "                    if self.v[s] >= 0:\n",
        "                        samples[i] = self.pi[s,a]*util_plus_derivative(r,self.alpha_)\n",
        "                    else:\n",
        "                        samples[i] = self.pi[s,a]*util_minus_derivative(r,self.beta_,self.lambda_)\n",
        "                samples = np.sort(samples,0)\n",
        "                for i in range(1, self.n_max+1):\n",
        "                    weights[sn,s] += samples[i-1]*(weight((self.n_max+1-i)/self.n_max, self.gamma_pos)-weight((self.n_max-i)/self.n_max, self.gamma_pos))\n",
        "        eps = 1e-16\n",
        "        h = (eps)*np.ones((self.S,1))\n",
        "        h[0] = 1\n",
        "        h = h/np.sum(h)\n",
        "        I = np.eye(self.S)\n",
        "        mu = np.linalg.inv((I-weights.T)+eps)@h\n",
        "        mu /= np.sum(mu)\n",
        "        return mu\n",
        "\n",
        "    def cpt_grad(self, s, acts, Rp, Rsigma):\n",
        "        mu = self.mu_cpt(acts, Rp, Rsigma)\n",
        "        grad = 0\n",
        "        acts_ = copy.deepcopy(acts)\n",
        "        for s in range(self.S):\n",
        "            grad_s = 0\n",
        "            for sn in range(self.S):\n",
        "                for a in range(self.A):\n",
        "                    acts_[self.id] = a\n",
        "                    sigma = (np.sum(acts_+1) - (a+1))/(self.num_visible_agents-1)\n",
        "                    r = Rp[self.id,s] + Rsigma[s] * sigma\n",
        "                    ret = r+self.discount*self.v[sn]\n",
        "                    if ret >= 0:\n",
        "                        u = util_plus(ret,self.alpha_)\n",
        "                        phi_der = util_plus_derivative(u,self.alpha_)\n",
        "                    else:\n",
        "                        u = -util_minus_abs(ret,self.beta_,self.lambda_)\n",
        "                        phi_der = util_minus_derivative(u,self.beta_,self.lambda_)\n",
        "                    pi_grad = self.pi[s,a]*(1-self.pi[s,a])\n",
        "                    grad_s = grad_s + phi_der*self.state_trans[s, self.calculate_joint_a(acts_), sn]*pi_grad*u\n",
        "            grad = grad + grad_s*float(mu[s])\n",
        "        return grad\n",
        "            \n",
        "    def learn(self, s, acts, Rp, Rsigma, it):\n",
        "        delta = self.cpt_delta(s, acts, Rp, Rsigma)\n",
        "        grad = self.cpt_grad(s, acts, Rp, Rsigma)\n",
        "        self.v[s] = self.v[s] + delta*self.lr_critic(it)\n",
        "        self.theta[s,acts[self.id]] = self.theta[s,acts[self.id]] + self.lr_actor(it)*grad\n",
        "        self.policy(s)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "seed = 2045\n",
        "\n",
        "np.random.seed(seed)\n",
        "pols_avg = np.zeros((N,S,A))\n",
        "\n",
        "Rp = np.random.rand(N,S)\n",
        "Rsigma = (np.random.rand(S)-0.5)*5\n",
        "pols_avg = np.zeros((N,S,A))\n",
        "max_it = int(1e04)\n",
        "\n",
        "\n",
        "discount = 0.99\n",
        "alpha_ = [0.65, 0.65, 0.65,0.65]\n",
        "beta_ = [0.65, 0.65, 0.65,0.65]\n",
        "lambda_ = [2.6, 2.6, 2.6,2.6]\n",
        "gamma_pos = [0.69, 0.69, 0.69,0.69]\n",
        "gamma_neg = [0.69, 0.69, 0.69,0.69]\n",
        "s = 0\n",
        "ep = 8\n",
        "all_v_it = np.zeros((ep,max_it,N,S))\n",
        "all_pols_it = np.zeros((ep,max_it,N,S,A))\n",
        "\n",
        "\n",
        "for e in range(ep):\n",
        "    np.random.seed(seed+ep)\n",
        "    s = 0\n",
        "    r = np.zeros((N,))\n",
        "    sigma = np.zeros((N,))\n",
        "    next_sigma = np.zeros((N,))\n",
        "    agents = []\n",
        "    counter = 0\n",
        "    for n in range(N):\n",
        "        agents.append(Agent(n, S, A, N-1, state_trans, n_max=50, discount=0.99, alpha_ = alpha_[n], beta_ = beta_[n],\\\n",
        "                 lambda_ = lambda_[n], gamma_pos = gamma_pos[n], gamma_neg = gamma_neg[n]))   \n",
        "    act = np.zeros((N,),dtype=int)\n",
        "    act[n] = agents[n].sel_action(s)\n",
        "    joint_a = 0\n",
        "    for it in range(1, max_it+1):\n",
        "        joint_a = 0\n",
        "        for n in range(N):\n",
        "            joint_a += int(A**n)*act[n]\n",
        "        sn = get_next_state(s, joint_a, P)\n",
        "        for n in range(N):\n",
        "            agents[n].learn(s, act, Rp, Rsigma, it)\n",
        "            all_v_it[e,it-1,n,:] = agents[n].v\n",
        "            all_pols_it[e,it-1,n,:] = agents[n].pi\n",
        "        for n in range(N):\n",
        "            act[n] = agents[n].sel_action_next(sn)\n",
        "        s = copy.deepcopy(sn)\n",
        "\n",
        "            \n",
        "    pols = (1/A)*np.ones((N,S,A))\n",
        "    for n in range(N):\n",
        "        pols[n] = agents[n].pi\n",
        "    pols_avg += pols\n",
        "pols = pols_avg/ep\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.5"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
